{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we dispose of original object ID's and remove duplicate vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg={\n",
    "    'main_folder':'/home/kvassay/data/sketch-testing/',\n",
    "    'dataset_file':'profi-neuralnet-100K.data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path=cfg['main_folder']+cfg['dataset_file']\n",
    "dataset_new_path=cfg['main_folder']+'dataset.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CaffeVectorsIterator(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.f = open(file_path, 'rb')\n",
    "        self.limit=limit\n",
    "        if self.limit is not None:\n",
    "            self.returned=0\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            # (id: int, vector: np array of float32)\n",
    "            if self.limit is not None:\n",
    "                if self.returned==self.limit:\n",
    "                    self.f.close()\n",
    "                    raise StopIteration\n",
    "                    \n",
    "            lineA = self.f.next()\n",
    "            lineB = self.f.next()\n",
    "            if self.limit is not None:\n",
    "                self.returned+=1\n",
    "                \n",
    "            return (int(lineA.split(' ')[2]),  np.fromstring(lineB, dtype='f', sep=' '))\n",
    "        except StopIteration:\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.f:\n",
    "            self.f.close()\n",
    "\n",
    "\n",
    "class CaffeVectorsIterable(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.file_path = file_path\n",
    "        self.limit=limit\n",
    "\n",
    "    def __iter__(self):\n",
    "        return CaffeVectorsIterator(self.file_path,limit=self.limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, decaf_vecs=zip(*[obj for obj in CaffeVectorsIterable(dataset_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decaf_vecs=np.matrix(decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecs=set()\n",
    "indicies=list()\n",
    "for i,vec in enumerate(decaf_vecs):\n",
    "    key=str(vec)\n",
    "    if not key in vecs:\n",
    "        indicies.append(i)\n",
    "        vecs.add(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decaf_vecs=decaf_vecs[np.array(indicies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86648, 4096)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(decaf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(dataset_new_path, 'wb') as f:\n",
    "    np.save(f,decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
