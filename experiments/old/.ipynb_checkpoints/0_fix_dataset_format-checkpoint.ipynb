{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we dispose of original object ID's and remove duplicate vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'main_folder': '/home/matej/data/sketch-testing/',\n",
    "    'dataset_file': 'profi-neuralnet-100K.data'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH=\n",
    "TRAIN_SET_SAVE_PATH=\n",
    "TEST_SET_SAVE_PATH="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaffeVectorsIterator(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.f = open(file_path, 'rb')\n",
    "        self.limit = limit\n",
    "        if self.limit is not None:\n",
    "            self.returned = 0\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            # (id: int, vector: np array of float32)\n",
    "            if self.limit is not None:\n",
    "                if self.returned == self.limit:\n",
    "                    self.f.close()\n",
    "                    raise StopIteration\n",
    "\n",
    "            lineA = self.f.next()\n",
    "            lineB = self.f.next()\n",
    "            if self.limit is not None:\n",
    "                self.returned += 1\n",
    "\n",
    "            return (int(lineA.split(' ')[2]), np.fromstring(lineB, dtype='f', sep=' '))\n",
    "        except StopIteration:\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.f:\n",
    "            self.f.close()\n",
    "\n",
    "\n",
    "class CaffeVectorsIterable(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.file_path = file_path\n",
    "        self.limit = limit\n",
    "\n",
    "    def __iter__(self):\n",
    "        return CaffeVectorsIterator(self.file_path, limit=self.limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, decaf_vecs=zip(*[obj for obj in CaffeVectorsIterable(dataset_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs=np.matrix(decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs=set()\n",
    "indicies=list()\n",
    "for i,vec in enumerate(decaf_vecs):\n",
    "    key=str(vec)\n",
    "    if not key in vecs:\n",
    "        indicies.append(i)\n",
    "        vecs.add(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs=decaf_vecs[np.array(indicies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(decaf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs, test_decaf_vecs=train_test_split(decaf_vecs,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69318, 4096)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17330, 4096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_new_path, 'wb') as f:\n",
    "    np.save(f,decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testset_path, 'wb') as f:\n",
    "    np.save(f,test_decaf_vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
