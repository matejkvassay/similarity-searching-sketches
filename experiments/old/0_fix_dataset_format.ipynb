{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we dispose of original object ID's and remove duplicate vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'main_folder': '/home/matej/data/sketch-testing/',\n",
    "    'dataset_file': 'profi-neuralnet-100K.data'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-e57e82860577>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-e57e82860577>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    RAW_DATA_PATH=\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_PATH=\n",
    "TRAIN_SET_SAVE_PATH=\n",
    "TEST_SET_SAVE_PATH="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaffeVectorsIterator(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.f = open(file_path, 'rb')\n",
    "        self.limit = limit\n",
    "        if self.limit is not None:\n",
    "            self.returned = 0\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            # (id: int, vector: np array of float32)\n",
    "            if self.limit is not None:\n",
    "                if self.returned == self.limit:\n",
    "                    self.f.close()\n",
    "                    raise StopIteration\n",
    "\n",
    "            lineA = self.f.next()\n",
    "            lineB = self.f.next()\n",
    "            if self.limit is not None:\n",
    "                self.returned += 1\n",
    "\n",
    "            return (int(lineA.split(' ')[2]), np.fromstring(lineB, dtype='f', sep=' '))\n",
    "        except StopIteration:\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.f:\n",
    "            self.f.close()\n",
    "\n",
    "\n",
    "class CaffeVectorsIterable(object):\n",
    "    def __init__(self, file_path, limit=None):\n",
    "        self.file_path = file_path\n",
    "        self.limit = limit\n",
    "\n",
    "    def __iter__(self):\n",
    "        return CaffeVectorsIterator(self.file_path, limit=self.limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, decaf_vecs=zip(*[obj for obj in CaffeVectorsIterable(dataset_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs=np.matrix(decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs=set()\n",
    "indicies=list()\n",
    "for i,vec in enumerate(decaf_vecs):\n",
    "    key=str(vec)\n",
    "    if not key in vecs:\n",
    "        indicies.append(i)\n",
    "        vecs.add(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs=decaf_vecs[np.array(indicies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(decaf_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs, test_decaf_vecs=train_test_split(decaf_vecs,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decaf_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_new_path, 'wb') as f:\n",
    "    np.save(f,decaf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testset_path, 'wb') as f:\n",
    "    np.save(f,test_decaf_vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
